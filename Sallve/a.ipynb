{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7b76be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usuario/.local/lib/python3.12/site-packages/pandas/core/arrays/masked.py:61: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando webscraping da Sallve...\n",
      "Coletando produtos em /collections/loja com paginação...\n",
      "Encontrados 138 links de produto (antes de filtro).\n",
      " [1/138] https://www.sallve.com.br/products/bastao-antioxidante-para-olhos\n",
      "   ✅ OK: Bastão Antiolheiras Antioxidante\n",
      " [2/138] https://www.sallve.com.br/products/kit-tudinho\n",
      "   ❌ Excluído por keyword (models): Kit Tudinho\n",
      " [3/138] https://www.sallve.com.br/collections/kits/products/kit-basicao\n",
      "   ❌ Excluído por keyword (models): Kit Basicão\n",
      " [4/138] https://www.sallve.com.br/products/protetor-solar-bastao-com-cor-antimanchas-fps-90\n",
      "   ✅ OK: Protetor Solar Bastão com Cor Antimanchas FPS 90\n",
      " [5/138] https://www.sallve.com.br/products/bastao-antiatrito\n",
      "   ✅ OK: Bastão Antiatrito\n",
      " [6/138] https://www.sallve.com.br/products/protetor-solar-bastao-fps60-muito-resistente\n",
      "   ✅ OK: Protetor Solar Bastão FPS 60 Muito Resistente\n",
      " [7/138] https://www.sallve.com.br/products/bastao-antioleosidade\n",
      "   ✅ OK: Bastão Antioleosidade\n",
      " [8/138] https://www.sallve.com.br/products/dupla-protecao-em-bastao\n",
      "   ❌ Excluído por keyword (models): Dupla Proteção em Bastão\n",
      " [9/138] https://www.sallve.com.br/products/dupla-rotina-pratica\n",
      "   ❌ Excluído por keyword (models): dupla rotina prática\n",
      " [10/138] https://www.sallve.com.br/products/limpador-enzimatico-em-po\n",
      "   ✅ OK: Limpador Enzimático em Pó\n",
      " [11/138] https://www.sallve.com.br/products/serum-para-cilios\n",
      "   ✅ OK: Sérum para Cílios\n",
      " [12/138] https://www.sallve.com.br/products/serum-antiolheiras\n",
      "   ✅ OK: Sérum Antiolheiras\n",
      " [13/138] https://www.sallve.com.br/products/creme-retexturizador-noturno\n",
      "   ✅ OK: Creme Retexturizador Noturno\n",
      " [14/138] https://www.sallve.com.br/products/hidratante-antioleosidade\n",
      "   ✅ OK: Hidratante Antioleosidade\n",
      " [15/138] https://www.sallve.com.br/products/super-niacinamida-20\n",
      "   ✅ OK: Super Niacinamida 20%\n",
      " [16/138] https://www.sallve.com.br/products/super-pro-colageno-10\n",
      "   ✅ OK: Super Pró-Colágeno 10%\n",
      " [17/138] https://www.sallve.com.br/products/retinol-serum-antissinais\n",
      "[fetch_soup] Erro em https://www.sallve.com.br/products/retinol-serum-antissinais: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "   ⚠️  Falha ao abrir página.\n",
      " [18/138] https://www.sallve.com.br/products/acido-hialuronico-hidratante-firmador\n",
      "   ✅ OK: Ácido Hialurônico Hidratante Firmador\n",
      " [19/138] https://www.sallve.com.br/products/vitamina-c-antioxidante-hidratante\n",
      "   ✅ OK: Vitamina C Antioxidante Hidratante\n",
      " [20/138] https://www.sallve.com.br/products/serum-antiacne\n",
      "   ✅ OK: Sérum Antiacne\n",
      " [21/138] https://www.sallve.com.br/products/serum-uniformizador\n",
      "   ✅ OK: Sérum Uniformizador\n",
      " [22/138] https://www.sallve.com.br/products/limpador-antioleosidade\n",
      "   ✅ OK: Limpador Antioleosidade\n",
      " [23/138] https://www.sallve.com.br/products/limpador-facial\n",
      "   ✅ OK: Limpador Facial\n",
      " [24/138] https://www.sallve.com.br/products/protetor-solar-toque-seco-fps50\n",
      "   ✅ OK: Protetor Solar Toque Seco FPS 50\n",
      " [25/138] https://www.sallve.com.br/products/tonico-antiacne\n",
      "   ✅ OK: Tônico Antiacne\n",
      " [26/138] https://www.sallve.com.br/products/super-vitamina-c-20\n",
      "   ✅ OK: Super Vitamina C 20%\n",
      " [27/138] https://www.sallve.com.br/products/dupla-rotina-noturna\n",
      "   ❌ Excluído por keyword (models): Dupla Rotina Noturna\n",
      " [28/138] https://www.sallve.com.br/products/dupla-sono-renovador\n",
      "   ❌ Excluído por keyword (models): Dupla Sono Renovador\n",
      " [29/138] https://www.sallve.com.br/products/dupla-renovacao-e-protecao-com-cor\n",
      "   ❌ Excluído por keyword (models): Dupla Renovação e Proteção - com Cor\n",
      " [30/138] https://www.sallve.com.br/products/dupla-acorda-e-vai\n",
      "   ❌ Excluído por keyword (models): Dupla Acorda e Vai\n",
      " [31/138] https://www.sallve.com.br/products/dupla-pele-descansada\n",
      "   ❌ Excluído por keyword (models): Dupla Pele Descansada\n",
      " [32/138] https://www.sallve.com.br/products/dupla-renovacao-e-protecao\n",
      "   ❌ Excluído por keyword (models): Dupla Renovação e Proteção\n",
      " [33/138] https://www.sallve.com.br/products/dupla-pele-mais-lisa\n",
      "   ❌ Excluído por keyword (models): Dupla Pele Mais Lisa\n",
      " [34/138] https://www.sallve.com.br/products/dupla-verao-na-bolsa\n",
      "   ❌ Excluído por keyword (models): Dupla de Treino\n",
      " [35/138] https://www.sallve.com.br/products/kit-rotina-antioleosidade\n",
      "   ❌ Excluído por keyword (models): kit rotina completa antioleosidade\n",
      " [36/138] https://www.sallve.com.br/products/trio-bastao\n",
      "   ✅ OK: Trio Bastão\n",
      " [37/138] https://www.sallve.com.br/products/dupla-renovacao-e-hidratacao\n",
      "   ❌ Excluído por keyword (models): Dupla Renovação e Hidratação\n",
      " [38/138] https://www.sallve.com.br/products/dupla-rotina-expressa\n",
      "   ❌ Excluído por keyword (models): Dupla Rotina Expressa\n",
      " [39/138] https://www.sallve.com.br/products/dupla-vitamina-c\n",
      "   ❌ Excluído por keyword (models): Dupla Vitamina C\n",
      " [40/138] https://www.sallve.com.br/products/dupla-cuidado-diario-pele-oleosa\n",
      "   ❌ Excluído por keyword (models): dupla cuidado diário - pele oleosa\n",
      " [41/138] https://www.sallve.com.br/products/dupla-antioleosidade-dia-e-noite\n",
      "   ❌ Excluído por keyword (models): dupla antioleosidade dia e noite\n",
      " [42/138] https://www.sallve.com.br/products/kit-antioleosidade\n",
      "   ❌ Excluído por keyword (models): Kit Antioleosidade\n",
      " [43/138] https://www.sallve.com.br/products/dupla-tratamento-area-dos-olhos\n",
      "   ❌ Excluído por keyword (models): Dupla Tratamento Área dos Olhos\n",
      " [44/138] https://www.sallve.com.br/products/dupla-olhar-renovado\n",
      "   ❌ Excluído por keyword (models): Dupla Olhar Renovado\n",
      " [45/138] https://www.sallve.com.br/products/dupla-limpa-acorda-e-revigora\n",
      "   ❌ Excluído por keyword (models): Dupla Limpa, Acorda e Revigora\n",
      " [46/138] https://www.sallve.com.br/products/dupla-vitamina-c-pele-sensivel\n",
      "   ❌ Excluído por keyword (models): Dupla Vitamina C - Pele Sensível\n",
      " [47/138] https://www.sallve.com.br/products/dupla-protecao-resistente\n",
      "   ❌ Excluído por keyword (models): Dupla Proteção Resistente\n",
      " [48/138] https://www.sallve.com.br/products/dupla-renova-e-repara\n",
      "   ❌ Excluído por keyword (models): Dupla Renova e Repara\n",
      " [49/138] https://www.sallve.com.br/products/dupla-colageno-e-retinol-puro-0-3\n",
      "   ❌ Excluído por keyword (models): Dupla Colágeno e Retinol Puro 0,3%\n",
      " [50/138] https://www.sallve.com.br/products/dupla-colageno-e-vitamina-c-20\n",
      "   ❌ Excluído por keyword (models): Dupla Colágeno e Vitamina C 20%\n",
      " [51/138] https://www.sallve.com.br/products/dupla-colageno-e-niacinamida-20\n",
      "   ❌ Excluído por keyword (models): Dupla Colágeno e Niacinamida 20%\n",
      " [52/138] https://www.sallve.com.br/products/dupla-niacinamida\n",
      "   ❌ Excluído por keyword (models): Dupla Niacinamida\n",
      " [53/138] https://www.sallve.com.br/products/dupla-colageno-e-vitamina-c\n",
      "   ❌ Excluído por keyword (models): Dupla Colágeno e Vitamina C\n",
      " [54/138] https://www.sallve.com.br/products/dupla-protecao-com-e-sem-cor\n",
      "   ❌ Excluído por keyword (models): Dupla Proteção - com e sem cor\n",
      " [55/138] https://www.sallve.com.br/products/retinol-puro-retinol-biomimetico\n",
      "   ❌ Excluído por keyword (models): Dupla Retinol Dia e Noite\n",
      " [56/138] https://www.sallve.com.br/products/dupla-retinol-e-vitamina-c-pele-sensivel\n",
      "   ❌ Excluído por keyword (models): Dupla Retinol e Vitamina C  - Pele Sensível\n",
      " [57/138] https://www.sallve.com.br/products/dupla-reducao-de-marcas\n",
      "   ❌ Excluído por keyword (models): Dupla Redução de Marcas\n",
      " [58/138] https://www.sallve.com.br/products/dupla-seca-e-nao-resseca\n",
      "   ❌ Excluído por keyword (models): Dupla Seca e Não Resseca\n",
      " [59/138] https://www.sallve.com.br/products/dupla-pele-mais-lisa-pele-sensivel\n",
      "   ❌ Excluído por keyword (models): Dupla Pele Mais Lisa - Pele Sensível\n",
      " [60/138] https://www.sallve.com.br/products/dupla-colageno-e-vitamina-c-pele-sensivel\n",
      "   ❌ Excluído por keyword (models): Dupla Colágeno e Vitamina C - Pele Sensível\n",
      " [61/138] https://www.sallve.com.br/products/trio-livre-de-acne\n",
      "   ✅ OK: Trio Livre de Acne\n",
      " [62/138] https://www.sallve.com.br/products/dupla-super-antiacne\n",
      "[fetch_soup] Erro em https://www.sallve.com.br/products/dupla-super-antiacne: HTTPSConnectionPool(host='www.sallve.com.br', port=443): Read timed out.\n",
      "   ⚠️  Falha ao abrir página.\n",
      " [63/138] https://www.sallve.com.br/products/dupla-antimarcas-dia\n",
      "   ❌ Excluído por keyword (models): Dupla Antimarcas - Dia\n",
      " [64/138] https://www.sallve.com.br/products/kit-antissinais-basicao\n",
      "   ❌ Excluído por keyword (models): Kit Antissinais Basicão\n",
      " [65/138] https://www.sallve.com.br/products/kit-antissinais-completao\n",
      "   ❌ Excluído por keyword (models): Kit Antissinais Completão\n",
      " [66/138] https://www.sallve.com.br/products/kit-novos-fios\n",
      "   ❌ Excluído por keyword (models): Dupla Novos Fios\n",
      " [67/138] https://www.sallve.com.br/products/dupla-cuidado-diario\n",
      "   ❌ Excluído por keyword (models): Dupla Cuidado Diário\n",
      " [68/138] https://www.sallve.com.br/products/dupla-adeus-assaduras\n",
      "   ❌ Excluído por keyword (models): Dupla Adeus, Assaduras\n",
      " [69/138] https://www.sallve.com.br/products/limpador-antiacne\n",
      "   ✅ OK: Limpador Antiacne\n",
      " [70/138] https://www.sallve.com.br/products/hidratante-facial\n",
      "   ✅ OK: Hidratante Facial\n",
      " [71/138] https://www.sallve.com.br/products/hidratante-reparador-labial\n",
      "   ✅ OK: Hidratante Reparador Labial\n",
      " [72/138] https://www.sallve.com.br/products/hidratante-reparador\n",
      "   ✅ OK: Hidratante Reparador\n",
      " [73/138] https://www.sallve.com.br/products/vitamina-c-acido-hialuronico-retinol\n",
      "   ✅ OK: vitamina c + ácido hialurônico + retinol puro\n",
      " [74/138] https://www.sallve.com.br/products/dupla-antiolheiras-e-antiatrito\n",
      "   ❌ Excluído por keyword (models): Dupla Antiolheiras e Antiatrito\n",
      " [75/138] https://www.sallve.com.br/products/dupla-esfoliante\n",
      "   ❌ Excluído por keyword (models): Dupla Esfoliante\n",
      " [76/138] https://www.sallve.com.br/products/esfoliante-enzimatico\n",
      "   ✅ OK: Esfoliante enzimático\n",
      " [77/138] https://www.sallve.com.br/products/esfoliante-hidratante-corporal\n",
      "   ❌ Excluído por keyword (models): Esfoliante Hidratante Corporal\n",
      " [78/138] https://www.sallve.com.br/products/hidratante-antiatrito\n",
      "   ✅ OK: Hidratante Antiatrito\n",
      " [79/138] https://www.sallve.com.br/products/super-acido-glicolico-10\n",
      "   ✅ OK: Super Ácido Glicólico 10%\n",
      " [80/138] https://www.sallve.com.br/products/super-acido-salicilico-2\n",
      "   ✅ OK: Super Ácido Salicílico 2%\n",
      " [81/138] https://www.sallve.com.br/products/kit-basicao-linha-antiacne\n",
      "   ❌ Excluído por keyword (models): Kit Basicão Antiacne\n",
      " [82/138] https://www.sallve.com.br/products/tonico-renovador\n",
      "   ✅ OK: Tônico Renovador\n",
      " [83/138] https://www.sallve.com.br/products/dupla-verao-na-bolsa-com-cor\n",
      "   ❌ Excluído por keyword (models): Dupla de Treino - com cor\n",
      " [84/138] https://www.sallve.com.br/products/spray-reparador-calmante\n",
      "   ✅ OK: Spray Reparador Calmante\n",
      " [85/138] https://www.sallve.com.br/products/vitamina-c-acido-salicilico\n",
      "[download_image] Falha ao baixar https://www.sallve.com.br/cdn/shop/files/antioxidante_antiacne.png?v=1707504591&width=700: HTTPSConnectionPool(host='www.sallve.com.br', port=443): Max retries exceeded with url: /cdn/shop/files/antioxidante_antiacne.png?v=1707504591&width=700 (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x75921990d160>: Failed to resolve 'www.sallve.com.br' ([Errno -3] Temporary failure in name resolution)\"))\n",
      "   ✅ OK: vitamina c + ácido salicílico\n",
      " [86/138] https://www.sallve.com.br/products/tonico-antiqueda\n",
      "   ❌ Excluído por keyword (models): Tônico Antiqueda Capilar\n",
      " [87/138] https://www.sallve.com.br/products/dupla-acorda-e-vai-toque-seco\n",
      "   ❌ Excluído por keyword (models): Dupla Acorda e Vai - toque seco\n",
      " [88/138] https://www.sallve.com.br/products/kit-basicao\n",
      "   ❌ Excluído por keyword (models): Kit Basicão\n",
      " [89/138] https://www.sallve.com.br/products/dupla-livre-de-pelos-encravados\n",
      "   ❌ Excluído por keyword (models): Dupla Livre de Pelos Encravados\n",
      " [90/138] https://www.sallve.com.br/products/dupla-cuidado-corporal\n",
      "   ❌ Excluído por keyword (models): Dupla Cuidado Corporal\n",
      " [91/138] https://www.sallve.com.br/products/hidratante-renovador-corporal\n",
      "   ❌ Excluído por keyword (models): Hidratante Renovador Corporal\n",
      " [92/138] https://www.sallve.com.br/products/protetor-solar-corporal-fps50\n",
      "   ❌ Excluído por keyword (models): Protetor Solar Corporal FPS 50\n",
      " [93/138] https://www.sallve.com.br/products/refil-limpador-facial\n",
      "   ✅ OK: Refil Limpador Facial\n",
      " [94/138] https://www.sallve.com.br/products/refil-limpador-antioleosidade\n",
      "   ✅ OK: Refil Limpador Antioleosidade\n",
      " [95/138] https://www.sallve.com.br/products/refil-limpador-antiacne\n",
      "   ✅ OK: Refil Limpador Antiacne\n",
      " [96/138] https://www.sallve.com.br/products/kit-2-unidades-refil-limpador-facial\n",
      "   ❌ Excluído por keyword (models): Kit 2 unidades Refil Limpador Facial\n",
      " [97/138] https://www.sallve.com.br/products/dupla-vitamina-c-hialuronico-retinol-biomimetico\n",
      "   ❌ Excluído por keyword (models): Dupla Vitamina C + Hialurônico + Retinol Biomimético\n",
      " [98/138] https://www.sallve.com.br/products/kit-controle-de-poros\n",
      "   ❌ Excluído por keyword (models): kit controle de poros\n",
      " [99/138] https://www.sallve.com.br/products/dupla-essencial\n",
      "   ❌ Excluído por keyword (models): Dupla Essencial\n",
      " [100/138] https://www.sallve.com.br/products/dupla-antiacne-e-antioleosidade\n",
      "   ❌ Excluído por keyword (models): Dupla Antiacne e Antioleosidade\n",
      " [101/138] https://www.sallve.com.br/products/dupla-antiatrito-e-antioleosidade\n",
      "   ❌ Excluído por keyword (models): Dupla Antiatrito e Antioleosidade\n",
      " [102/138] https://www.sallve.com.br/products/dupla-antioleosidade\n",
      "   ❌ Excluído por keyword (models): Dupla Antioleosidade\n",
      " [103/138] https://www.sallve.com.br/products/trio-pele-sequinha\n",
      "   ✅ OK: trio pele sequinha\n",
      " [104/138] https://www.sallve.com.br/products/trio-essencial-pele-oleosa\n",
      "   ✅ OK: trio essencial - pele oleosa\n",
      " [105/138] https://www.sallve.com.br/products/dupla-livre-de-oleosidade\n",
      "   ❌ Excluído por keyword (models): dupla livre de oleosidade\n",
      " [106/138] https://www.sallve.com.br/products/dupla-super-antioleosidade\n",
      "   ❌ Excluído por keyword (models): dupla super antioleosidade\n",
      " [107/138] https://www.sallve.com.br/products/dupla-antiolheiras-e-antioleosidade\n",
      "   ❌ Excluído por keyword (models): Dupla Antiolheiras e Antioleosidade\n",
      " [108/138] https://www.sallve.com.br/products/dupla-anti-cravo-dia-e-noite\n",
      "   ❌ Excluído por keyword (models): Dupla Anti Cravo Dia e Noite\n",
      " [109/138] https://www.sallve.com.br/products/kit-anticravo-gentil\n",
      "   ❌ Excluído por keyword (models): Kit Anticravo Gentil\n",
      " [110/138] https://www.sallve.com.br/products/dupla-anti-cravo\n",
      "   ❌ Excluído por keyword (models): Dupla anti cravo\n",
      " [111/138] https://www.sallve.com.br/products/dupla-efeito-imediato\n",
      "   ❌ Excluído por keyword (models): Dupla Efeito Imediato\n",
      " [112/138] https://www.sallve.com.br/products/dupla-renovacao-dia-e-noite\n",
      "   ❌ Excluído por keyword (models): Dupla Renovação Dia e Noite\n",
      " [113/138] https://www.sallve.com.br/products/dupla-antiolheiras-dia-e-noite\n",
      "   ❌ Excluído por keyword (models): Dupla Antiolheiras Dia e Noite\n",
      " [114/138] https://www.sallve.com.br/products/dupla-antiolheiras-e-protecao-antimanchas\n",
      "   ❌ Excluído por keyword (models): Dupla Antiolheiras e Proteção Antimanchas\n",
      " [115/138] https://www.sallve.com.br/products/dupla-olhar-radiante\n",
      "   ❌ Excluído por keyword (models): Dupla Olhar Radiante\n",
      " [116/138] https://www.sallve.com.br/products/dupla-menos-olheiras-mais-firmeza\n",
      "   ❌ Excluído por keyword (models): Dupla Menos Olheiras, Mais Firmeza\n",
      " [117/138] https://www.sallve.com.br/products/dupla-menos-olheiras-mais-vico\n",
      "   ❌ Excluído por keyword (models): Dupla Menos Olheiras, Mais Viço\n",
      " [118/138] https://www.sallve.com.br/products/dupla-antiolheiras-e-protecao-sequinha\n",
      "   ❌ Excluído por keyword (models): Dupla Antiolheiras e Proteção Sequinha\n",
      " [119/138] https://www.sallve.com.br/products/dupla-antiolheiras-e-antimarcas\n",
      "   ❌ Excluído por keyword (models): Dupla Antiolheiras e Antimarcas\n",
      " [120/138] https://www.sallve.com.br/products/dupla-uniformizadora\n",
      "   ❌ Excluído por keyword (models): Dupla Uniformizadora\n",
      " [121/138] https://www.sallve.com.br/products/dupla-livre-de-olheiras-e-oleosidade\n",
      "   ❌ Excluído por keyword (models): Dupla Livre de Olheiras e Oleosidade\n",
      " [122/138] https://www.sallve.com.br/products/dupla-antiolheiras-e-anticravos\n",
      "   ❌ Excluído por keyword (models): Dupla Antiolheiras e Anticravos\n",
      " [123/138] https://www.sallve.com.br/products/protetor-solar-com-cor-fps-60\n",
      "[download_image] Falha ao baixar https://www.sallve.com.br/Liquid error (sections/product-regular-main line 360): invalid url input: 404 Client Error: Not Found for url: https://www.sallve.com.br/Liquid%20error%20(sections/product-regular-main%20line%20360):%20invalid%20url%20input\n",
      "   ✅ OK: Protetor Solar com Cor Toque Seco FPS 60\n",
      " [124/138] https://www.sallve.com.br/products/kit-rotina-completa-antiacne\n",
      "   ❌ Excluído por keyword (models): Kit Rotina Completa Antiacne\n",
      " [125/138] https://www.sallve.com.br/products/dupla-antiacne-rosto-e-corpo\n",
      "   ❌ Excluído por keyword (models): Dupla Antiacne Rosto e Corpo\n",
      " [126/138] https://www.sallve.com.br/products/spray-corporal-antiacne\n",
      "   ❌ Excluído por keyword (models): Spray Antiacne Corporal\n",
      " [127/138] https://www.sallve.com.br/products/protetor-solar-fps60\n",
      "   ✅ OK: Protetor Solar FPS 60\n",
      " [128/138] https://www.sallve.com.br/products/oleo-antissinais\n",
      "   ✅ OK: Óleo Antissinais\n",
      " [129/138] https://www.sallve.com.br/products/hidratante-corporal-antioxidante\n",
      "   ❌ Excluído por keyword (models): Hidratante Corporal Antioxidante\n",
      " [130/138] https://www.sallve.com.br/products/oleo-facial-antioxidante\n",
      "   ✅ OK: Óleo Facial Antioxidante\n",
      " [131/138] https://www.sallve.com.br/products/vitamina-c-fps-30-antioxidante-hidratante\n",
      "   ✅ OK: Vitamina C FPS 30 Antioxidante Hidratante\n",
      " [132/138] https://www.sallve.com.br/products/mascara-antirressaca\n",
      "   ✅ OK: Máscara Antirressaca\n",
      " [133/138] https://www.sallve.com.br/products/oleo-corporal-antioxidante\n",
      "   ❌ Excluído por keyword (models): Óleo Corporal Antioxidante\n",
      " [134/138] https://www.sallve.com.br/products/vitamina-c-antioxidante-hidratante-pele-sensivel\n",
      "   ✅ OK: Vitamina C Antioxidante Hidratante Pele Sensível\n",
      " [135/138] https://www.sallve.com.br/products/dupla-cuidado-diario-pele-sensivel\n",
      "   ❌ Excluído por keyword (models): Dupla Cuidado Diário - Pele Sensível\n",
      " [136/138] https://www.sallve.com.br/products/kit-rotina-renovacao\n",
      "   ❌ Excluído por keyword (models): Kit Rotina Renovação\n",
      " [137/138] https://www.sallve.com.br/products/kit-rotina-anticravo\n",
      "   ❌ Excluído por keyword (models): Kit Rotina Anticravo\n",
      " [138/138] https://www.sallve.com.br/products/dupla-queridinhos-da-rede-vizinha-com-cor\n",
      "   ❌ Excluído por keyword (models): Dupla Queridinhos da Rede Vizinha - com cor\n",
      "Total pós-filtro: 47\n",
      "\n",
      "Coletando tipos de pele via filtros da Sallve...\n",
      " - Filtro 'seca': https://www.sallve.com.br/collections/super-ativos?filter.p.m.filter.skin_type=pele+seca\n",
      "[skin-type-collect] Erro na página: https://www.sallve.com.br/collections/super-ativos?filter.p.m.filter.skin_type=pele+seca&page=2 -> HTTPSConnectionPool(host='www.sallve.com.br', port=443): Read timed out. (read timeout=30)\n",
      "   · 21 nome(s) coletado(s)\n",
      " - Filtro 'mista': https://www.sallve.com.br/collections/super-ativos?filter.p.m.filter.skin_type=pele+mista\n",
      "[skin-type-collect] Erro na página: https://www.sallve.com.br/collections/super-ativos?filter.p.m.filter.skin_type=pele+mista&page=1 -> HTTPSConnectionPool(host='www.sallve.com.br', port=443): Max retries exceeded with url: /collections/super-ativos?filter.p.m.filter.skin_type=pele+mista&page=1 (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x759219aa20f0>: Failed to resolve 'www.sallve.com.br' ([Errno -3] Temporary failure in name resolution)\"))\n",
      "   · 0 nome(s) coletado(s)\n",
      " - Filtro 'sensível': https://www.sallve.com.br/collections/super-ativos?filter.p.m.filter.skin_type=pele+sens%C3%ADvel\n",
      "   · 11 nome(s) coletado(s)\n",
      " - Filtro 'normal': https://www.sallve.com.br/collections/super-ativos?filter.p.m.filter.skin_type=pele+normal\n",
      "[skin-type-collect] Erro na página: https://www.sallve.com.br/collections/super-ativos?filter.p.m.filter.skin_type=pele+normal&page=5 -> HTTPSConnectionPool(host='www.sallve.com.br', port=443): Read timed out.\n",
      "   · 24 nome(s) coletado(s)\n",
      " - Filtro 'oleosa': https://www.sallve.com.br/collections/super-ativos?filter.p.m.filter.skin_type=pele+oleosa\n",
      "[skin-type-collect] Erro na página: https://www.sallve.com.br/collections/super-ativos?filter.p.m.filter.skin_type=pele+oleosa&page=1 -> HTTPSConnectionPool(host='www.sallve.com.br', port=443): Max retries exceeded with url: /collections/super-ativos?filter.p.m.filter.skin_type=pele+oleosa&page=1 (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x75921a0db1d0>: Failed to resolve 'www.sallve.com.br' ([Errno -3] Temporary failure in name resolution)\"))\n",
      "   · 0 nome(s) coletado(s)\n",
      " - Filtro 'todos os tipos': https://www.sallve.com.br/collections/super-ativos?filter.p.m.filter.skin_type=todos+os+tipos+de+pele\n",
      "   · 13 nome(s) coletado(s)\n",
      "\n",
      "Dados salvos:\n",
      "  - JSON: sallve_products.json (47 produtos)\n",
      "  - CSV:  sallve_products.csv  (47 produtos)\n",
      "\n",
      "Concluído! Produtos extraídos: 47\n",
      "Imagens salvas em: /home/usuario/Área de trabalho/Dados/Sallve/imagem\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# Scraper Sallve — completo, com categorias (arquivo category), benefícios/ingredientes (models),\n",
    "# tipos de pele (sinônimos + filtros), download de imagem e saída JSON/CSV.\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import unicodedata\n",
    "from urllib.parse import urljoin, urlparse, parse_qs, urlencode\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Optional\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# ==== Imports dos seus módulos ====\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "from skin import (\n",
    "    SKIN_TYPE_CANONICAL_ORDER,\n",
    "    SKIN_TYPE_SYNONYMS_PT,\n",
    ")\n",
    "\n",
    "from exclude import (\n",
    "    EXCLUDE_KEYWORDS,\n",
    ")\n",
    "\n",
    "from ingredient import (\n",
    "    INGREDIENTES_VALIDOS,\n",
    ")\n",
    "\n",
    "from benefits import (\n",
    "    BENEFIT_SYNONYMS_PT,\n",
    "    BENEFIT_CANONICAL_ORDER,\n",
    ")\n",
    "\n",
    "# categorias (agora importamos HINTS também)\n",
    "from category import (\n",
    "    CATEGORY_CANONICAL_ORDER,\n",
    "    CATEGORY_HINTS,\n",
    ")\n",
    "\n",
    "# ==== Configs/site ====\n",
    "BASE_URL = \"https://www.sallve.com.br\"\n",
    "COLLECTION_URL = \"https://www.sallve.com.br/collections/loja\"\n",
    "\n",
    "# filtros por tipo de pele (para enriquecer depois)\n",
    "SKIN_FILTER_URLS = {\n",
    "    \"seca\":      \"https://www.sallve.com.br/collections/super-ativos?filter.p.m.filter.skin_type=pele+seca\",\n",
    "    \"mista\":     \"https://www.sallve.com.br/collections/super-ativos?filter.p.m.filter.skin_type=pele+mista\",\n",
    "    \"sensível\":  \"https://www.sallve.com.br/collections/super-ativos?filter.p.m.filter.skin_type=pele+sens%C3%ADvel\",\n",
    "    \"normal\":    \"https://www.sallve.com.br/collections/super-ativos?filter.p.m.filter.skin_type=pele+normal\",\n",
    "    \"oleosa\":    \"https://www.sallve.com.br/collections/super-ativos?filter.p.m.filter.skin_type=pele+oleosa\",\n",
    "    \"todos os tipos\": \"https://www.sallve.com.br/collections/super-ativos?filter.p.m.filter.skin_type=todos+os+tipos+de+pele\",\n",
    "}\n",
    "\n",
    "HEADERS = {\n",
    "    \"User-Agent\": (\n",
    "        \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "        \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "        \"Chrome/120.0.0.0 Safari/537.36\"\n",
    "    )\n",
    "}\n",
    "\n",
    "IMAGES_DIR = Path(\"imagem\")\n",
    "IMAGES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ==== Helpers de normalização ====\n",
    "def _strip_accents_lower(s: str) -> str:\n",
    "    if not s:\n",
    "        return \"\"\n",
    "    s = \"\".join(c for c in unicodedata.normalize(\"NFD\", s) if unicodedata.category(c) != \"Mn\")\n",
    "    s = s.lower()\n",
    "    s = s.replace(\"-\", \" \")\n",
    "    s = re.sub(r\"[^\\w\\s]\", \" \", s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "\n",
    "def _safe_join_url(url: str) -> str:\n",
    "    return \"https:\" + url if url.startswith(\"//\") else url\n",
    "\n",
    "def _tokenize_ingredientes(texto: str):\n",
    "    if not texto:\n",
    "        return []\n",
    "    texto = texto.replace(\"\\n\", \" \").replace(\"\\r\", \" \")\n",
    "    partes = re.split(r\"[;,·•|\\u2022]|(?:\\s{2,})|,|\\.\", texto)\n",
    "    return [p.strip() for p in partes if p and p.strip()]\n",
    "\n",
    "def _padroniza_por_lista(tokens, lista_validos):\n",
    "    valid_norm_map = {_strip_accents_lower(v): v for v in lista_validos}\n",
    "    padronizados, vistos = [], set()\n",
    "    for tok in tokens:\n",
    "        n = _strip_accents_lower(tok)\n",
    "        if \"hialuronato\" in n and \"sodio\" in n and \"acido hialuronico\" in valid_norm_map:\n",
    "            key = \"acido hialuronico\"\n",
    "        elif \"matrixyl\" in n:\n",
    "            key = _strip_accents_lower(\"peptídeos matrixyl\")\n",
    "        else:\n",
    "            key = None\n",
    "            for kn in valid_norm_map.keys():\n",
    "                if n == kn or n.startswith(kn) or kn in n:\n",
    "                    key = kn\n",
    "                    break\n",
    "        if key and key not in vistos:\n",
    "            padronizados.append(valid_norm_map[key])\n",
    "            vistos.add(key)\n",
    "    return padronizados\n",
    "\n",
    "def _add_or_replace_page_param(url: str, page: int) -> str:\n",
    "    parsed = urlparse(url)\n",
    "    q = parse_qs(parsed.query, keep_blank_values=True)\n",
    "    q[\"page\"] = [str(page)]\n",
    "    new_query = urlencode({k: v[0] if isinstance(v, list) and len(v) == 1 else v for k, v in q.items()}, doseq=True)\n",
    "    return parsed._replace(query=new_query).geturl()\n",
    "\n",
    "def _sanitize_filename(name: str) -> str:\n",
    "    base = _strip_accents_lower(name)\n",
    "    base = re.sub(r\"[^a-z0-9]+\", \"-\", base).strip(\"-\")\n",
    "    base = re.sub(r\"-{2,}\", \"-\", base)\n",
    "    return base or \"produto\"\n",
    "\n",
    "def _normalize_price_text(txt: str) -> str | None:\n",
    "    if not txt:\n",
    "        return None\n",
    "    t = re.sub(r\"\\s+\", \" \", txt).strip().replace(\"\\xa0\", \" \")\n",
    "    m = re.search(r\"R\\$\\s*\\d{1,3}(?:\\.\\d{3})*,\\d{2}\", t)\n",
    "    if m:\n",
    "        p = m.group(0)\n",
    "        p = re.sub(r\"\\s+\", \" \", p).replace(\"R$ \", \"R$ \").strip()\n",
    "        return p\n",
    "    m2 = re.search(r\"\\d{1,3}(?:\\.\\d{3})*,\\d{2}\", t)\n",
    "    if m2:\n",
    "        return \"R$ \" + m2.group(0)\n",
    "    return None\n",
    "\n",
    "def should_exclude_product(product_name: str) -> bool:\n",
    "    if not product_name:\n",
    "        return True\n",
    "    t = product_name.lower()\n",
    "    return any(k in t for k in EXCLUDE_KEYWORDS)\n",
    "\n",
    "# ==== Coleta de URLs da collection ====\n",
    "def get_product_links_from_collection(max_pages: int = 8):\n",
    "    links, vistos = [], set()\n",
    "    for page in range(1, max_pages + 1):\n",
    "        url = f\"{COLLECTION_URL}?page={page}\"\n",
    "        try:\n",
    "            r = requests.get(url, headers=HEADERS, timeout=30)\n",
    "            if r.status_code != 200:\n",
    "                break\n",
    "            soup = BeautifulSoup(r.content, \"html.parser\")\n",
    "            for a in soup.find_all(\"a\", href=True):\n",
    "                href = a[\"href\"]\n",
    "                if \"/products/\" in href:\n",
    "                    full = urljoin(BASE_URL, href)\n",
    "                    if full not in vistos:\n",
    "                        vistos.add(full)\n",
    "                        links.append(full)\n",
    "            time.sleep(0.7)\n",
    "        except Exception as e:\n",
    "            print(f\"[get_product_links_from_collection] Erro na página {page}: {e}\")\n",
    "            break\n",
    "    return links\n",
    "\n",
    "# ==== Ingredientes (filtrado pela whitelist do models) ====\n",
    "def extract_ingredients(soup: BeautifulSoup) -> str:\n",
    "    ingredientes_brutos = []\n",
    "    area_ing = soup.find(\"div\", class_=re.compile(r\"\\btabcontent\\b.*\\bingredients\\b\", re.I))\n",
    "    if area_ing:\n",
    "        for h2 in area_ing.find_all(\"h2\"):\n",
    "            txt = h2.get_text(\" \", strip=True)\n",
    "            if txt:\n",
    "                ingredientes_brutos.append(txt)\n",
    "        resume = area_ing.find(\"div\", class_=re.compile(r\"\\bingredients_resume\\b\", re.I))\n",
    "        if resume:\n",
    "            raw = resume.get_text(\"\\n\", strip=True)\n",
    "            raw_norm = _strip_accents_lower(raw)\n",
    "            i1 = raw_norm.find(\"ingredientes:\")\n",
    "            if i1 != -1:\n",
    "                bloco_raw = raw[i1 + len(\"ingredientes:\") :]\n",
    "                for stopper in [\"ingredientes em portugues:\", \"ingredientes em português:\"]:\n",
    "                    cut_idx = _strip_accents_lower(bloco_raw).find(stopper)\n",
    "                    if cut_idx != -1:\n",
    "                        bloco_raw = bloco_raw[:cut_idx]\n",
    "                        break\n",
    "                ingredientes_brutos.extend(_tokenize_ingredientes(bloco_raw))\n",
    "            for key in [\"ingredientes em portugues:\", \"ingredientes em português:\"]:\n",
    "                j = raw_norm.find(key)\n",
    "                if j != -1:\n",
    "                    bloco_pt = raw[j + len(key) :]\n",
    "                    ingredientes_brutos.extend(_tokenize_ingredientes(bloco_pt))\n",
    "                    break\n",
    "\n",
    "    tokens = []\n",
    "    for item in ingredientes_brutos:\n",
    "        if not item:\n",
    "            continue\n",
    "        t = item.strip().strip(\":\").strip()\n",
    "        if not t:\n",
    "            continue\n",
    "        if len(t.split()) > 8 and \",\" not in t and \";\" not in t:\n",
    "            continue\n",
    "        tokens.append(t)\n",
    "\n",
    "    padronizados = _padroniza_por_lista(tokens, INGREDIENTES_VALIDOS)\n",
    "    return \"; \".join(padronizados)\n",
    "\n",
    "# ==== Benefícios (padronização via models) ====\n",
    "def padroniza_beneficios(textos_beneficios: List[str]) -> List[str]:\n",
    "    if not textos_beneficios:\n",
    "        return []\n",
    "    encontrados = set()\n",
    "    norm_syn = {\n",
    "        canonico: [_strip_accents_lower(s) for s in patt_list if s]\n",
    "        for canonico, patt_list in BENEFIT_SYNONYMS_PT.items()\n",
    "    }\n",
    "    for txt in textos_beneficios:\n",
    "        n = _strip_accents_lower(txt)\n",
    "        for canonico, padds in norm_syn.items():\n",
    "            if any(patt in n for patt in padds):\n",
    "                encontrados.add(canonico)\n",
    "    if BENEFIT_CANONICAL_ORDER:\n",
    "        order_map = {name: i for i, name in enumerate(BENEFIT_CANONICAL_ORDER)}\n",
    "        return sorted(list(encontrados), key=lambda x: order_map.get(x, 999))\n",
    "    return sorted(list(encontrados))\n",
    "\n",
    "def extract_beneficios(soup: BeautifulSoup) -> str:\n",
    "    candidatos = []\n",
    "    # bloco típico da Sallve\n",
    "    for det in soup.find_all(\"details\", class_=re.compile(r\"\\bDifferentials\\b\", re.I)):\n",
    "        for li in det.find_all(\"li\"):\n",
    "            txt = li.get_text(\" \", strip=True)\n",
    "            if not txt:\n",
    "                continue\n",
    "            tnorm = _strip_accents_lower(txt)\n",
    "            if re.fullmatch(r\"\\d+(?:[.,]\\d+)?\", tnorm):\n",
    "                continue\n",
    "            if any(w in tnorm for w in [\"ponto\", \"pontos\", \"minha sallve\"]):\n",
    "                continue\n",
    "            if len(txt) <= 200:\n",
    "                candidatos.append(txt)\n",
    "\n",
    "    # fallback: lista qualquer curta na página\n",
    "    if not candidatos:\n",
    "        main = soup.find(\"article\", class_=re.compile(r\"\\bRegularMain__content\\b\"))\n",
    "        cont = main or soup\n",
    "        for li in cont.find_all(\"li\"):\n",
    "            txt = li.get_text(\" \", strip=True)\n",
    "            if txt and len(txt) <= 160:\n",
    "                candidatos.append(txt)\n",
    "\n",
    "    cats = padroniza_beneficios(candidatos)\n",
    "    return \"; \".join(cats)\n",
    "\n",
    "# ==== Imagem principal ====\n",
    "def _pick_best_from_srcset(srcset: str) -> str:\n",
    "    best_url, best_w = None, -1\n",
    "    for part in srcset.split(\",\"):\n",
    "        part = part.strip()\n",
    "        if not part:\n",
    "            continue\n",
    "        m = re.match(r\"(.+?)\\s+(\\d+)w\", part)\n",
    "        if m:\n",
    "            url, w = m.group(1).strip(), int(m.group(2))\n",
    "            if w > best_w:\n",
    "                best_url, best_w = url, w\n",
    "        else:\n",
    "            if best_url is None:\n",
    "                best_url = part\n",
    "    return best_url\n",
    "\n",
    "def extract_image_url(soup: BeautifulSoup) -> Optional[str]:\n",
    "    img = soup.find(\"img\", class_=re.compile(r\"\\bview__image\\b\", re.I))\n",
    "    candidates = []\n",
    "    if img:\n",
    "        if img.get(\"srcset\"):\n",
    "            candidates.append(_pick_best_from_srcset(img[\"srcset\"]))\n",
    "        if img.get(\"src\"):\n",
    "            candidates.append(img[\"src\"])\n",
    "    if not candidates:\n",
    "        for im in soup.find_all(\"img\"):\n",
    "            classes = \" \".join(im.get(\"class\", []))\n",
    "            if re.search(r\"(product|image|gallery|media|hero|view)\", classes, re.I):\n",
    "                if im.get(\"srcset\"):\n",
    "                    candidates.append(_pick_best_from_srcset(im[\"srcset\"]))\n",
    "                if im.get(\"src\"):\n",
    "                    candidates.append(im.get(\"src\"))\n",
    "    if not candidates:\n",
    "        meta = soup.find(\"meta\", property=\"og:image\")\n",
    "        if meta and meta.get(\"content\"):\n",
    "            candidates.append(meta[\"content\"])\n",
    "    for url in candidates:\n",
    "        if not url:\n",
    "            continue\n",
    "        url = _safe_join_url(url.strip())\n",
    "        return urljoin(BASE_URL, url)\n",
    "    return None\n",
    "\n",
    "def _infer_ext_from_url(url: str) -> str:\n",
    "    path = urlparse(url).path\n",
    "    ext = os.path.splitext(path)[1].lower()\n",
    "    if ext in [\".jpg\", \".jpeg\", \".png\", \".webp\", \".gif\"]:\n",
    "        return ext if ext != \".jpeg\" else \".jpg\"\n",
    "    return \".jpg\"\n",
    "\n",
    "def download_image(image_url: str, product_name: str) -> Optional[str]:\n",
    "    if not image_url:\n",
    "        return None\n",
    "    try:\n",
    "        r = requests.get(image_url, headers=HEADERS, timeout=40)\n",
    "        r.raise_for_status()\n",
    "        ext = _infer_ext_from_url(image_url)\n",
    "        base = _sanitize_filename(product_name)\n",
    "        filename = f\"{base}{ext}\"\n",
    "        dest = IMAGES_DIR / filename\n",
    "        counter = 1\n",
    "        while dest.exists():\n",
    "            filename = f\"{base}-{counter}{ext}\"\n",
    "            dest = IMAGES_DIR / filename\n",
    "            counter += 1\n",
    "        with open(dest, \"wb\") as f:\n",
    "            f.write(r.content)\n",
    "        return filename\n",
    "    except Exception as e:\n",
    "        print(f\"[download_image] Falha ao baixar {image_url}: {e}\")\n",
    "        return None\n",
    "\n",
    "# ==== Preço / Tamanho / Nome / Subtítulo ====\n",
    "def extract_price(soup: BeautifulSoup) -> Optional[str]:\n",
    "    # tenta classes mais específicas primeiro\n",
    "    for cls_pat in [r\"\\bTotalPrice\\b\", r\"\\bTotalPrice__CTA\\b\"]:\n",
    "        el = soup.find([\"strong\", \"span\"], class_=re.compile(cls_pat, re.I))\n",
    "        if el and el.get_text(strip=True):\n",
    "            p = _normalize_price_text(el.get_text(\" \", strip=True))\n",
    "            if p:\n",
    "                return p\n",
    "    box = soup.find(class_=re.compile(r\"\\bProductPrice\\b\", re.I))\n",
    "    if box:\n",
    "        p = _normalize_price_text(box.get_text(\" \", strip=True))\n",
    "        if p:\n",
    "            return p\n",
    "        strong = box.find(\"strong\")\n",
    "        if strong:\n",
    "            p = _normalize_price_text(strong.get_text(\" \", strip=True))\n",
    "            if p:\n",
    "                return p\n",
    "    generic = soup.find(class_=re.compile(r\"price\", re.I))\n",
    "    if generic:\n",
    "        p = _normalize_price_text(generic.get_text(\" \", strip=True))\n",
    "        if p:\n",
    "            return p\n",
    "    p = _normalize_price_text(soup.get_text(\" \", strip=True))\n",
    "    return p\n",
    "\n",
    "def extract_size(soup: BeautifulSoup) -> Optional[str]:\n",
    "    size_element = soup.find(\"span\", class_=re.compile(r\"\\bProductWeight\\b\", re.I))\n",
    "    if size_element:\n",
    "        return size_element.get_text(strip=True)\n",
    "    for alt in [\n",
    "        soup.find(class_=re.compile(r\"weight\", re.I)),\n",
    "        soup.find(class_=re.compile(r\"size\", re.I)),\n",
    "        soup.find(class_=re.compile(r\"volume\", re.I)),\n",
    "        soup.find(class_=re.compile(r\"quantity\", re.I)),\n",
    "    ]:\n",
    "        if alt and alt.get_text(strip=True):\n",
    "            text = alt.get_text(strip=True)\n",
    "            m = re.search(r\"\\d+\\,?\\d*\\s*(?:ml|g|mg|kg|l|oz)\", text, re.I)\n",
    "            if m:\n",
    "                return m.group()\n",
    "    return None\n",
    "\n",
    "def extract_subtitle(soup: BeautifulSoup) -> Optional[str]:\n",
    "    # tenta alguns seletores comuns\n",
    "    for sel in [\n",
    "        \"p.ProductSubtitle\", \"p.product-subtitle\",\n",
    "        \".product__subtitle\", \".product__text\", \".product__text.inline-richtext\",\n",
    "        \".ProductSummary\", \".ProductDescription p\",\n",
    "    ]:\n",
    "        node = soup.select_one(sel)\n",
    "        if node and node.get_text(strip=True):\n",
    "            st = node.get_text(\" \", strip=True)\n",
    "            return st if len(st) <= 220 else st[:220]\n",
    "    return None\n",
    "\n",
    "def extract_name(soup: BeautifulSoup) -> Optional[str]:\n",
    "    name_element = soup.find(\"span\", id=\"ProductNameTitle\")\n",
    "    if name_element and name_element.get_text(strip=True):\n",
    "        return name_element.get_text(strip=True)\n",
    "    for alt in [\n",
    "        soup.find(\"h1\"),\n",
    "        soup.find(\"h2\"),\n",
    "        soup.find(\"title\"),\n",
    "        soup.find(class_=re.compile(r\"product.*title\", re.I)),\n",
    "        soup.find(class_=re.compile(r\"\\bname\\b\", re.I)),\n",
    "    ]:\n",
    "        if alt and alt.get_text(strip=True):\n",
    "            return alt.get_text(strip=True)\n",
    "    return None\n",
    "\n",
    "def fetch_soup(url: str) -> Optional[BeautifulSoup]:\n",
    "    try:\n",
    "        r = requests.get(url, headers=HEADERS, timeout=30)\n",
    "        if r.status_code != 200:\n",
    "            return None\n",
    "        return BeautifulSoup(r.content, \"html.parser\")\n",
    "    except Exception as e:\n",
    "        print(f\"[fetch_soup] Erro em {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "# ==== Categoria (usando CATEGORY_HINTS + ordem canônica) ====\n",
    "_CAT_ORDER_MAP = {c: i for i, c in enumerate(CATEGORY_CANONICAL_ORDER)}\n",
    "\n",
    "def _norm_plain(s: str) -> str:\n",
    "    return _strip_accents_lower(s or \"\")\n",
    "\n",
    "def classify_category(name: str, description: str | None = None) -> Optional[str]:\n",
    "    txt = _norm_plain(f\"{name or ''} {description or ''}\")\n",
    "    hits = []\n",
    "    for cat, needles in CATEGORY_HINTS.items():\n",
    "        for needle in needles:\n",
    "            if _norm_plain(needle) and _norm_plain(needle) in txt:\n",
    "                hits.append(cat)\n",
    "                break\n",
    "    if not hits:\n",
    "        return None\n",
    "    hits.sort(key=lambda c: _CAT_ORDER_MAP.get(c, 10_000))\n",
    "    return hits[0]\n",
    "\n",
    "# ==== Tipos de pele (por sinônimos do models) ====\n",
    "_SKIN_SYNONYMS_NORM = {\n",
    "    canonico: [_strip_accents_lower(x) for x in lst if x]\n",
    "    for canonico, lst in SKIN_TYPE_SYNONYMS_PT.items()\n",
    "}\n",
    "_SKIN_ORDER_MAP = {name: i for i, name in enumerate(SKIN_TYPE_CANONICAL_ORDER or [])}\n",
    "\n",
    "def _classify_skin_types_from_strings(*strings: str) -> List[str]:\n",
    "    big = _strip_accents_lower(\" \".join(s for s in strings if s))\n",
    "    found = set()\n",
    "    for canonico, pats in _SKIN_SYNONYMS_NORM.items():\n",
    "        if any(p and p in big for p in pats):\n",
    "            found.add(canonico)\n",
    "    if not found:\n",
    "        return []\n",
    "    return sorted(found, key=lambda x: _SKIN_ORDER_MAP.get(x, 10_000))\n",
    "\n",
    "# ==== Produto ====\n",
    "def extract_product_data_from_soup(soup: BeautifulSoup, product_url: str, nome: str) -> Dict:\n",
    "    subtitulo_txt = extract_subtitle(soup)\n",
    "    beneficios_txt = extract_beneficios(soup) or \"\"\n",
    "    ingredientes_txt = extract_ingredients(soup) or \"\"\n",
    "    preco_txt = extract_price(soup) or \"\"\n",
    "    tamanho_txt = extract_size(soup) or \"\"\n",
    "\n",
    "    # categoria pelo nome + subtítulo\n",
    "    categoria = classify_category(nome, subtitulo_txt) or \"\"\n",
    "\n",
    "    # tipos de pele por texto (nome, subtítulo, benefícios)\n",
    "    tipos_detectados = _classify_skin_types_from_strings(nome, subtitulo_txt or \"\", beneficios_txt)\n",
    "\n",
    "    data = {\n",
    "        \"marca\": \"sallve\",\n",
    "        \"nome\": nome,\n",
    "        \"categoria\": categoria,\n",
    "        \"subtitulo\": subtitulo_txt,\n",
    "        \"tamanho_quantidade\": tamanho_txt,\n",
    "        \"preco\": preco_txt,\n",
    "        \"ingredientes\": ingredientes_txt,\n",
    "        \"beneficios\": beneficios_txt,\n",
    "        \"tipo_pele\": \"; \".join(tipos_detectados) if tipos_detectados else \"\",\n",
    "        \"imagem\": \"\",\n",
    "        \"url\": product_url,\n",
    "    }\n",
    "\n",
    "    # imagem\n",
    "    img_url = extract_image_url(soup)\n",
    "    if img_url:\n",
    "        img_filename = download_image(img_url, nome)\n",
    "        if img_filename:\n",
    "            data[\"imagem\"] = img_filename\n",
    "\n",
    "    return data\n",
    "\n",
    "# ==== Scrape listagem -> produtos ====\n",
    "def scrape_sallve_products() -> List[Dict]:\n",
    "    print(\"Iniciando webscraping da Sallve...\")\n",
    "    print(\"Coletando produtos em /collections/loja com paginação...\")\n",
    "    product_links = get_product_links_from_collection(max_pages=8)\n",
    "    if not product_links:\n",
    "        print(\"Nenhum produto encontrado na coleção. (Checar HTML/seletores)\")\n",
    "        return []\n",
    "\n",
    "    print(f\"Encontrados {len(product_links)} links de produto (antes de filtro).\")\n",
    "    products = []\n",
    "\n",
    "    for i, url in enumerate(product_links, 1):\n",
    "        print(f\" [{i}/{len(product_links)}] {url}\")\n",
    "        soup = fetch_soup(url)\n",
    "        if not soup:\n",
    "            print(\"   ⚠️  Falha ao abrir página.\")\n",
    "            continue\n",
    "\n",
    "        nome = extract_name(soup)\n",
    "        if not nome:\n",
    "            print(\"   ⚠️  Nome não encontrado.\")\n",
    "            continue\n",
    "\n",
    "        if should_exclude_product(nome):\n",
    "            print(f\"   ❌ Excluído por keyword (models): {nome}\")\n",
    "            continue\n",
    "\n",
    "        prod = extract_product_data_from_soup(soup, url, nome)\n",
    "        products.append(prod)\n",
    "        print(f\"   ✅ OK: {nome}\")\n",
    "        time.sleep(0.7)\n",
    "\n",
    "    print(f\"Total pós-filtro: {len(products)}\")\n",
    "    return products\n",
    "\n",
    "# ==== Coleta auxiliar para enriquecer tipos de pele via filtros do site ====\n",
    "def _collect_collection_products_with_pagination(collection_url: str, max_pages: int = 20):\n",
    "    encontrados = set()\n",
    "    for page in range(1, max_pages + 1):\n",
    "        page_url = _add_or_replace_page_param(collection_url, page)\n",
    "        try:\n",
    "            r = requests.get(page_url, headers=HEADERS, timeout=30)\n",
    "            if r.status_code != 200:\n",
    "                break\n",
    "            soup = BeautifulSoup(r.content, \"html.parser\")\n",
    "            anchors = soup.find_all(\"a\", href=True)\n",
    "            page_found = 0\n",
    "            for a in anchors:\n",
    "                href = a[\"href\"]\n",
    "                if \"/products/\" in href:\n",
    "                    text = a.get_text(\" \", strip=True) or \"\"\n",
    "                    if not text:\n",
    "                        img = a.find(\"img\", alt=True)\n",
    "                        if img and img.get(\"alt\"):\n",
    "                            text = img[\"alt\"]\n",
    "                    if text:\n",
    "                        page_found += 1\n",
    "                        encontrados.add(_strip_accents_lower(text))\n",
    "            if page_found == 0:\n",
    "                break\n",
    "            time.sleep(0.5)\n",
    "        except Exception as e:\n",
    "            print(f\"[skin-type-collect] Erro na página: {page_url} -> {e}\")\n",
    "            break\n",
    "    return encontrados\n",
    "\n",
    "def enrich_with_skin_types(products: List[Dict]) -> List[Dict]:\n",
    "    if not products:\n",
    "        return products\n",
    "\n",
    "    print(\"\\nColetando tipos de pele via filtros da Sallve...\")\n",
    "    name_to_idx = {}\n",
    "    for idx, p in enumerate(products):\n",
    "        n = _strip_accents_lower(p.get(\"nome\", \"\"))\n",
    "        if n:\n",
    "            name_to_idx.setdefault(n, set()).add(idx)\n",
    "\n",
    "    for canonical, url in SKIN_FILTER_URLS.items():\n",
    "        print(f\" - Filtro '{canonical}': {url}\")\n",
    "        norm_names = _collect_collection_products_with_pagination(url, max_pages=20)\n",
    "        print(f\"   · {len(norm_names)} nome(s) coletado(s)\")\n",
    "        for nn in norm_names:\n",
    "            if nn in name_to_idx:\n",
    "                for idx in name_to_idx[nn]:\n",
    "                    current = products[idx].get(\"tipo_pele\", \"\") or \"\"\n",
    "                    tipos = [t.strip() for t in current.split(\";\") if t.strip()]\n",
    "                    if canonical not in tipos:\n",
    "                        tipos.append(canonical)\n",
    "                    if SKIN_TYPE_CANONICAL_ORDER:\n",
    "                        order = {v: i for i, v in enumerate(SKIN_TYPE_CANONICAL_ORDER)}\n",
    "                        tipos = sorted(tipos, key=lambda x: order.get(x, 999))\n",
    "                    products[idx][\"tipo_pele\"] = \"; \".join(tipos)\n",
    "        time.sleep(0.6)\n",
    "\n",
    "    # default se ficou vazio\n",
    "    for p in products:\n",
    "        if not (p.get(\"tipo_pele\") or \"\").strip():\n",
    "            p[\"tipo_pele\"] = \"todos os tipos\"\n",
    "\n",
    "    return products\n",
    "\n",
    "# ==== Persistência ====\n",
    "def save_data(products_data: List[Dict]):\n",
    "    if not products_data:\n",
    "        print(\"Nenhum dado para salvar.\")\n",
    "        return\n",
    "\n",
    "    clean = []\n",
    "    for p in products_data:\n",
    "        clean.append({\n",
    "            \"marca\": p.get(\"marca\"),\n",
    "            \"nome\": p.get(\"nome\"),\n",
    "            \"categoria\": p.get(\"categoria\"),\n",
    "            \"subtitulo\": p.get(\"subtitulo\"),\n",
    "            \"tamanho_quantidade\": p.get(\"tamanho_quantidade\"),\n",
    "            \"preco\": p.get(\"preco\"),\n",
    "            \"ingredientes\": p.get(\"ingredientes\"),\n",
    "            \"beneficios\": p.get(\"beneficios\"),\n",
    "            \"tipo_pele\": p.get(\"tipo_pele\"),\n",
    "            \"imagem\": p.get(\"imagem\"),\n",
    "            \"url\": p.get(\"url\"),\n",
    "        })\n",
    "\n",
    "    # JSON\n",
    "    with open(\"sallve_products.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(clean, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    # CSV\n",
    "    df = pd.DataFrame(clean)\n",
    "    df.to_csv(\"sallve_products.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "    print(\"\\nDados salvos:\")\n",
    "    print(f\"  - JSON: sallve_products.json ({len(clean)} produtos)\")\n",
    "    print(f\"  - CSV:  sallve_products.csv  ({len(clean)} produtos)\")\n",
    "\n",
    "# ==== Main ====\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        data = scrape_sallve_products()\n",
    "        data = enrich_with_skin_types(data)\n",
    "        save_data(data)\n",
    "        print(f\"\\nConcluído! Produtos extraídos: {len(data)}\")\n",
    "        print(f\"Imagens salvas em: {IMAGES_DIR.resolve()}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nERRO: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

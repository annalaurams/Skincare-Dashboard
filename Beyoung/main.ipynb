{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981d9c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URLs de produtos encontrados na coleção: 25\n",
      "Registros válidos coletados: 23\n",
      "CSV salvo em: beyoung_skincare.csv\n",
      "{'site': 'beyoung', 'nome': 'Sérum facial com Retinol + Niacinamida', 'subtitulo': 'Aging Care', 'preco': '129.90', 'quantidade': '30ml', 'beneficios': 'hidratação, limpeza, antissinais, uniformiza o tom, antioxidante, esfoliação, acalma, luminosidade, fortalece a barreira, proteção solar, fortalece os fios, compatível com maquiagem, resultados rápidos', 'ingredientes': 'ácido cítrico, ácido glicólico, ácido hialurônico, ácido linoleico, ácido salicílico, ácido tranexâmico, alpha arbutin, cafeína, esqualano, fenoxietanol, hipoalergênico, lecitina, lha, niacinamida, pantenol, propanodiol, retinol, vitamina c, vitamina e', 'url': 'https://www.beyoung.com.br/products/aging-care'}\n",
      "{'site': 'beyoung', 'nome': 'Água Micelar Hidratante', 'subtitulo': 'Micellar Water', 'preco': '44.86', 'quantidade': '200ml', 'beneficios': 'hidratação, limpeza, controle da oleosidade, antissinais, antioxidante, esfoliação, acalma, proteção solar, crescimento de cílios/sobrancelhas, compatível com maquiagem', 'ingredientes': 'ácido glicólico, ácido hialurônico, ácido salicílico, ácido tranexâmico, alpha arbutin, cafeína, esqualano, lha, niacinamida, pantenol, retinol, vitamina c, vitamina e', 'url': 'https://www.beyoung.com.br/products/agua-micelar-hidratante'}\n",
      "{'site': 'beyoung', 'nome': 'Água Micelar Hidratante', 'subtitulo': 'Micellar Water', 'preco': '44.86', 'quantidade': '200ml', 'beneficios': 'hidratação, limpeza, controle da oleosidade, antissinais, antioxidante, esfoliação, acalma, proteção solar, crescimento de cílios/sobrancelhas, compatível com maquiagem', 'ingredientes': 'ácido glicólico, ácido hialurônico, ácido salicílico, ácido tranexâmico, alpha arbutin, cafeína, esqualano, lha, niacinamida, pantenol, retinol, vitamina c, vitamina e', 'url': 'https://www.beyoung.com.br/products/agua-micelar-hidratante#judgeme_product_reviews'}\n",
      "{'site': 'beyoung', 'nome': 'Hidratante facial em gel com ácido hialurônico (pele refrescante)', 'subtitulo': 'Hydra Gel', 'preco': '52.72', 'quantidade': '30ml', 'beneficios': 'hidratação, limpeza, controle da oleosidade, antissinais, uniformiza o tom, antioxidante, luminosidade, fortalece a barreira, fortalece os fios, compatível com maquiagem', 'ingredientes': 'ácido glicólico, ácido hialurônico, ácido salicílico, ácido tranexâmico, alpha arbutin, cafeína, disodium edta, esqualano, glycerin, lha, niacinamida, pantenol, phenoxyethanol, retinol, vitamina c, vitamina e', 'url': 'https://www.beyoung.com.br/products/beyoung-hydra-gel'}\n",
      "{'site': 'beyoung', 'nome': 'Sérum Facial Booster Multifuncional 3 em 1', 'subtitulo': 'Sérum Multifuncional Antioxidante', 'preco': '69.90', 'quantidade': '30ml', 'beneficios': 'hidratação, limpeza, controle da oleosidade, antissinais, uniformiza o tom, antioxidante, acalma, luminosidade, fortalece a barreira, proteção solar, fortalece os fios, compatível com maquiagem', 'ingredientes': 'ácido glicólico, ácido hialurônico, ácido salicílico, ácido tranexâmico, alpha arbutin, benzoato de sódio, cafeína, esqualano, fenoxietanol, lha, niacinamida, pantenol, peptídeo de cobre, retinol, vitamina c, vitamina e', 'url': 'https://www.beyoung.com.br/products/booster'}\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# Extração Beyoung (collections/skincare) — célula única para Jupyter\n",
    "# Requisitos: requests, selectolax\n",
    "\n",
    "import re\n",
    "import csv\n",
    "import time, sys, os, unicodedata\n",
    "from typing import List, Dict, Optional\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "import requests\n",
    "from selectolax.parser import HTMLParser\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "from skin import (\n",
    "    SKIN_TYPE_CANONICAL_ORDER,\n",
    "    SKIN_TYPE_SYNONYMS_PT,\n",
    ")\n",
    "\n",
    "from exclude import (\n",
    "    EXCLUDE_KEYWORDS,\n",
    ")\n",
    "\n",
    "from ingredient import (\n",
    "    INGREDIENTES_VALIDOS,\n",
    ")\n",
    "\n",
    "from benefits import (\n",
    "    BENEFIT_SYNONYMS_PT,\n",
    "    BENEFIT_CANONICAL_ORDER,\n",
    ")\n",
    "\n",
    "\n",
    "# ==== Configs básicas ====\n",
    "BASE = \"https://www.beyoung.com.br\"\n",
    "COLLECTION_URL = \"https://www.beyoung.com.br/collections/skincare\"\n",
    "SITE_LABEL = \"beyoung\"\n",
    "OUT_CSV = \"beyoung_skincare.csv\"\n",
    "HEADERS = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 \"\n",
    "                  \"(KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36\",\n",
    "    \"Accept-Language\": \"pt-BR,pt;q=0.9,en;q=0.8\"\n",
    "}\n",
    "\n",
    "# ==== Utils ====\n",
    "def get_html(url: str) -> Optional[HTMLParser]:\n",
    "    try:\n",
    "        resp = requests.get(url, headers=HEADERS, timeout=30)\n",
    "        if resp.ok:\n",
    "            return HTMLParser(resp.text)\n",
    "    except Exception:\n",
    "        pass\n",
    "    return None\n",
    "\n",
    "def text(node) -> str:\n",
    "    return (node.text().strip() if node else \"\").strip()\n",
    "\n",
    "def norm_spaces(s: str) -> str:\n",
    "    return re.sub(r\"\\s+\", \" \", s or \"\").strip()\n",
    "\n",
    "def strip_accents(s: str) -> str:\n",
    "    if not s: return \"\"\n",
    "    return \"\".join(c for c in unicodedata.normalize(\"NFD\", s) if unicodedata.category(c) != \"Mn\")\n",
    "\n",
    "def norm_for_match(s: str) -> str:\n",
    "    s = norm_spaces(s).lower()\n",
    "    s = strip_accents(s)\n",
    "    return s\n",
    "\n",
    "def price_to_float(s: str) -> Optional[float]:\n",
    "    if not s:\n",
    "        return None\n",
    "    m = re.search(r\"(\\d{1,3}(?:\\.\\d{3})*|\\d+)(?:,(\\d{2}))?\", s.replace(\"\\xa0\",\" \").replace(\"\\n\",\" \"))\n",
    "    if not m:\n",
    "        return None\n",
    "    inteiro = m.group(1).replace(\".\", \"\")\n",
    "    centavos = m.group(2) or \"00\"\n",
    "    try:\n",
    "        return float(f\"{inteiro}.{centavos}\")\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def has_excluded_keyword(name: str) -> bool:\n",
    "    n = norm_for_match(name)\n",
    "    for kw in EXCLUDE_KEYWORDS:\n",
    "        if kw and norm_for_match(kw) in n:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def guess_quantity(name: str, fallback: str = \"\") -> str:\n",
    "    patterns = [\n",
    "        r\"(\\d+)\\s*(ml|g|kg|l|L)\\b\",\n",
    "        r\"(\\d+,\\d+)\\s*(ml|g|kg|l|L)\\b\",\n",
    "        r\"\\b(\\d{2,4})\\s*(ml)\\b\",\n",
    "    ]\n",
    "    for pat in patterns:\n",
    "        m = re.search(pat, name, flags=re.IGNORECASE)\n",
    "        if m:\n",
    "            return \"\".join(m.groups()).replace(\" \", \"\")\n",
    "    return fallback.strip()\n",
    "\n",
    "# ==== Coleta de URLs da coleção ====\n",
    "def extract_product_urls_from_collection(doc: HTMLParser) -> List[str]:\n",
    "    urls = set()\n",
    "\n",
    "    for a in doc.css(\"a.full-unstyled-link\"):\n",
    "        href = a.attributes.get(\"href\", \"\")\n",
    "        if href and \"/products/\" in href:\n",
    "            urls.add(urljoin(BASE, href))\n",
    "\n",
    "    for a in doc.css(\"a.card__heading, a.product-grid-item, a.product-item\"):\n",
    "        href = a.attributes.get(\"href\", \"\")\n",
    "        if href and \"/products/\" in href:\n",
    "            urls.add(urljoin(BASE, href))\n",
    "\n",
    "    for a in doc.css(\"a\"):\n",
    "        href = a.attributes.get(\"href\", \"\")\n",
    "        if href and \"/products/\" in href:\n",
    "            urls.add(urljoin(BASE, href))\n",
    "\n",
    "    return sorted(urls)\n",
    "\n",
    "# ==== Classificação de BENEFÍCIOS (models) ====\n",
    "def collect_benefits_text(doc: HTMLParser) -> str:\n",
    "    \"\"\"\n",
    "    Varre trechos típicos de descrição para montar um texto base\n",
    "    onde buscaremos sinônimos de benefícios.\n",
    "    \"\"\"\n",
    "    parts = []\n",
    "\n",
    "    # Blocos comuns de descrição em Shopify\n",
    "    for sel in [\n",
    "        \".product__description\", \".product__description.rte\", \".rte\",\n",
    "        \".product__accordion\", \".accordion__content\", \".product__text\",\n",
    "        \"section, article\"\n",
    "    ]:\n",
    "        for n in doc.css(sel):\n",
    "            t = norm_spaces(n.text())\n",
    "            if t and len(t) > 40:\n",
    "                parts.append(t)\n",
    "\n",
    "    joined = \" \".join(parts)\n",
    "    if not joined:\n",
    "        joined = norm_spaces(doc.body.text() if doc.body else \"\")\n",
    "    return joined\n",
    "\n",
    "def classify_benefits(doc: HTMLParser) -> str:\n",
    "    \"\"\"\n",
    "    Retorna rótulos canônicos (separados por vírgula) em ordem de BENEFIT_CANONICAL_ORDER.\n",
    "    Se nada casado, retorna string vazia.\n",
    "    \"\"\"\n",
    "    txt = norm_for_match(collect_benefits_text(doc))\n",
    "    found = set()\n",
    "\n",
    "    for canonical, synonyms in BENEFIT_SYNONYMS_PT.items():\n",
    "        for syn in synonyms:\n",
    "            if syn and norm_for_match(syn) in txt:\n",
    "                found.add(canonical)\n",
    "                break\n",
    "\n",
    "    if not found:\n",
    "        return \"\"\n",
    "    ordered = [b for b in BENEFIT_CANONICAL_ORDER if b in found]\n",
    "    return \", \".join(ordered)\n",
    "\n",
    "# ==== Filtragem de INGREDIENTES (models) ====\n",
    "def collect_ingredients_text(doc: HTMLParser) -> str:\n",
    "    \"\"\"\n",
    "    Junta trechos que costumam listar composição/ativos.\n",
    "    \"\"\"\n",
    "    parts = []\n",
    "    # Títulos/âncoras comuns\n",
    "    anchors = (\"COMPOSIÇÃO\", \"COMPOSICAO\", \"INGREDIENTES\", \"ATIVOS\", \"PRINCIPAIS ATIVOS\")\n",
    "    for node in doc.css(\"strong, b, h1, h2, h3\"):\n",
    "        title = norm_spaces(node.text()).upper()\n",
    "        if any(a in title for a in anchors):\n",
    "            # pega alguns irmãos seguintes\n",
    "            hops, cur = 0, node\n",
    "            while cur and hops < 12:\n",
    "                cur = cur.next\n",
    "                if not cur: break\n",
    "                try:\n",
    "                    # cur pode ser Node ou str; só pega Node com .text()\n",
    "                    t = getattr(cur, \"text\", None)\n",
    "                    if t:\n",
    "                        val = norm_spaces(cur.text())\n",
    "                        if val:\n",
    "                            parts.append(val)\n",
    "                except Exception:\n",
    "                    pass\n",
    "                hops += 1\n",
    "\n",
    "    if not parts:\n",
    "        # fallback: corpo todo\n",
    "        parts = [norm_spaces(doc.body.text() if doc.body else \"\")]\n",
    "    return \" \".join(parts)\n",
    "\n",
    "def filter_ingredients(doc: HTMLParser) -> str:\n",
    "    \"\"\"\n",
    "    Retorna apenas ingredientes presentes em INGREDIENTES_VALIDOS (ordem alfabética).\n",
    "    \"\"\"\n",
    "    txt = norm_for_match(collect_ingredients_text(doc))\n",
    "    hits = set()\n",
    "    for ing in INGREDIENTES_VALIDOS:\n",
    "        if norm_for_match(ing) in txt:\n",
    "            hits.add(ing)\n",
    "    if not hits:\n",
    "        return \"\"\n",
    "    # ordena alfabeticamente desconsiderando acentos/caixa\n",
    "    return \", \".join(sorted(hits, key=lambda s: strip_accents(s).lower()))\n",
    "\n",
    "# ==== Extração de um produto ====\n",
    "def extract_product_data(url: str) -> Optional[Dict]:\n",
    "    doc = get_html(url)\n",
    "    if not doc:\n",
    "        return None\n",
    "\n",
    "    # Nome\n",
    "    name_node = doc.css_first(\"h1.product__title\") or doc.css_first(\"h1.product__title.hd3\")\n",
    "    name = text(name_node)\n",
    "\n",
    "    # Subtítulo\n",
    "    subtitle_node = doc.css_first(\"p.product__text.inline-richtext\") or doc.css_first(\".product__subtitle, .product__text\")\n",
    "    subtitle = text(subtitle_node)\n",
    "\n",
    "    # Preço\n",
    "    price_selectors = [\n",
    "        \"span.f-price-item.f-price-item--sale\",\n",
    "        \"span.price-item.price-item--sale\",\n",
    "        \"span.price-item.price-item--regular\",\n",
    "        \"span.money\",\n",
    "        \"[data-product-price] .price-item--sale\",\n",
    "        \".price__container .price-item--sale\",\n",
    "        \".price__regular .price-item--regular\",\n",
    "    ]\n",
    "    raw_price = \"\"\n",
    "    for sel in price_selectors:\n",
    "        node = doc.css_first(sel)\n",
    "        if node and node.text().strip():\n",
    "            raw_price = node.text().strip()\n",
    "            break\n",
    "    price = price_to_float(raw_price)\n",
    "\n",
    "    # Quantidade\n",
    "    qty_node = doc.css_first('[data-selected-swatch-value=\"Tamanho\"]') or doc.css_first(\"label[for*='template'][for*='main'][for*='-0']\")\n",
    "    quantity = text(qty_node) or guess_quantity(name, \"\")\n",
    "\n",
    "    # Filtros\n",
    "    if not name or has_excluded_keyword(name):\n",
    "        return None\n",
    "\n",
    "    # >>> NOVO: Benefícios e Ingredientes padronizados <<<\n",
    "    beneficios = classify_benefits(doc)       # só rótulos canônicos do models\n",
    "    ingredientes = filter_ingredients(doc)    # só itens whitelist do models\n",
    "\n",
    "    return {\n",
    "        \"site\": SITE_LABEL,\n",
    "        \"nome\": name,\n",
    "        \"subtitulo\": subtitle,\n",
    "        \"preco\": f\"{price:.2f}\" if price is not None else \"\",\n",
    "        \"quantidade\": quantity,\n",
    "        \"beneficios\": beneficios,     # <- apenas os canônicos reconhecidos\n",
    "        \"ingredientes\": ingredientes, # <- apenas os whitelist do models\n",
    "        \"url\": url\n",
    "    }\n",
    "\n",
    "# ==== Paginação da coleção ====\n",
    "def paginate_collection(base_url: str, sleep_s: float = 0.8, max_pages: int = 50) -> List[str]:\n",
    "    all_urls = set()\n",
    "    page = 1\n",
    "    while page <= max_pages:\n",
    "        url = f\"{base_url}?page={page}\"\n",
    "        doc = get_html(url)\n",
    "        if not doc:\n",
    "            break\n",
    "        urls = extract_product_urls_from_collection(doc)\n",
    "        if not urls:\n",
    "            if page == 1 and base_url != url:\n",
    "                doc0 = get_html(base_url)\n",
    "                if doc0:\n",
    "                    urls0 = extract_product_urls_from_collection(doc0)\n",
    "                    for u in urls0:\n",
    "                        all_urls.add(u)\n",
    "            break\n",
    "        for u in urls:\n",
    "            all_urls.add(u)\n",
    "        page += 1\n",
    "        time.sleep(sleep_s)\n",
    "    return sorted(all_urls)\n",
    "\n",
    "# ==== Escrita CSV ====\n",
    "def write_csv(rows: List[Dict], path: str):\n",
    "    fieldnames = [\"site\", \"nome\", \"subtitulo\", \"preco\", \"quantidade\", \"beneficios\", \"ingredientes\", \"url\"]\n",
    "    with open(path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        w = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "        w.writeheader()\n",
    "        for r in rows:\n",
    "            w.writerow({k: r.get(k, \"\") for k in fieldnames})\n",
    "\n",
    "# ==== Execução ====\n",
    "all_product_urls = paginate_collection(COLLECTION_URL)\n",
    "print(f\"URLs de produtos encontrados na coleção: {len(all_product_urls)}\")\n",
    "\n",
    "rows = []\n",
    "for i, purl in enumerate(all_product_urls, 1):\n",
    "    data = extract_product_data(purl)\n",
    "    if data:\n",
    "        rows.append(data)\n",
    "    time.sleep(0.6 if i % 3 else 1.0)\n",
    "\n",
    "write_csv(rows, OUT_CSV)\n",
    "print(f\"Registros válidos coletados: {len(rows)}\")\n",
    "print(f\"CSV salvo em: {OUT_CSV}\")\n",
    "\n",
    "# Visualização de amostra\n",
    "for r in rows[:5]:\n",
    "    print(r)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

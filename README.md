# ğŸ§´ AnÃ¡lise de Dados sobre Produtos de Cuidados Faciais: Um Estudo sobre as TendÃªncias do Mercado Brasileiro


## ğŸ“‘ SumÃ¡rio

1. [VisÃ£o Geral](#-visÃ£o-geral)
2. [Estrutura do Projeto](#-estrutura-do-projeto)
3. [ConteÃºdo das Pastas](#-conteÃºdo-das-pastas)
   - [Pasta de Marca (Template)](#pasta-de-marca-template)
   - [Interface (Dashboard)](#interface-dashboard)
   - [Models (NormalizaÃ§Ã£o)](#models-normalizaÃ§Ã£o)
4. [Formatos de Dados](#-formatos-de-dados)
   - [CSV Padronizado](#csv-padronizado)
   - [JSON Schema](#json-schema)
5. [ConfiguraÃ§Ã£o e ExecuÃ§Ã£o](#%EF%B8%8F-configuraÃ§Ã£o-e-execuÃ§Ã£o)
   - [1. Preparar o Ambiente](#1-preparar-o-ambiente)
   - [2. Gerar os Dados](#2-gerar-os-dados)
   - [3. Rodar o Dashboard](#3-rodar-o-dashboard)
6. [PÃ¡ginas do Dashboard](#-pÃ¡ginas-do-dashboard)
7. [DependÃªncias](#-dependÃªncias)
8. [Checklist de ImplementaÃ§Ã£o](#-checklist-de-implementaÃ§Ã£o)

---

## ğŸŒŸ VisÃ£o Geral

O projeto visa construir um pipeline completo para:

- **Extrair** dados de produtos de skincare de marcas brasileiras (Oceane, Sallve, Creamy, BeYoung, Ollie)
- **Normalizar** informaÃ§Ãµes (categorias, benefÃ­cios, ingredientes, tipos de pele) usando mÃ³dulos prÃ³prios
- **Visualizar** dashboard filtros e rankings

---

## ğŸ“‚ Estrutura do Projeto
```
DADOS/
â”œâ”€â”€ Arquivo/                        # CSVs marcas
â”œâ”€â”€ marcas/                         # Dados das marcas
â”‚   â”œâ”€â”€ Beyoung/
â”‚   â”‚   â”œâ”€â”€ images/                 # Imagens baixadas
â”‚   â”‚   â”œâ”€â”€ Beyoung_products.csv    # CSV padronizado
â”‚   â”‚   â”œâ”€â”€ Beyoung_products.json   # JSON original (opcional)
â”‚   â”‚   â””â”€â”€ main.ipynb              # Web scraping
â”‚   â”œâ”€â”€ Creamy/
â”‚   â”‚   â””â”€â”€ ... (mesma estrutura)
â”‚   â”œâ”€â”€ Oceane/
â”‚   â”‚   â””â”€â”€ ... (mesma estrutura)
â”‚   â”œâ”€â”€ Ollie/
â”‚   â”‚   â””â”€â”€ ... (mesma estrutura)
â”‚   â””â”€â”€ Sallve/
â”‚       â””â”€â”€ ... (mesma estrutura)
â”œâ”€â”€ Interface/                      # Streamlit
â”‚   â”œâ”€â”€ .streamlit/                 # ConfiguraÃ§Ãµes do Streamlit
â”‚   â”‚   â””â”€â”€ config.toml             # Tema e configuraÃ§Ãµes
â”‚   â”œâ”€â”€ core/                       
â”‚   â”‚   â”œâ”€â”€ data.py                 # Carregamento e validaÃ§Ã£o
â”‚   â”‚   â””â”€â”€ utils.py                # FunÃ§Ãµes auxiliares
â”‚   â”œâ”€â”€ pages/                      # PÃ¡ginas do dashboard
â”‚   â”‚   â”œâ”€â”€ 1_CatÃ¡logo.py
â”‚   â”‚   â”œâ”€â”€ 2_Ingredientes.py
â”‚   â”‚   â”œâ”€â”€ 3_BenefÃ­cios.py
â”‚   â”‚   â””â”€â”€ 4_Tipos_de_Pele.py
â”‚   â”œâ”€â”€ ui_components/              # Componentes reutilizÃ¡veis
â”‚   â”‚   â”œâ”€â”€ filters.py              
â”‚   â”‚   â””â”€â”€ cards.py                
â”‚   â”œâ”€â”€ Principal.py                # PÃ¡gina inicial (entry point)
â”‚   â””â”€â”€ requirements.txt            # DependÃªncias do dashboard
â”œâ”€â”€ models/                         # Regras de normalizaÃ§Ã£o
â”‚   â”œâ”€â”€ benefits.py                 
â”‚   â”œâ”€â”€ category.py                 
â”‚   â”œâ”€â”€ ingredient.py               
â”‚   â””â”€â”€ skin.py                     
â”œâ”€â”€ models_sem_filtro/              
â””â”€â”€ README.md                       # Este arquivo
```

---

## ğŸ“‹ ConteÃºdo das Pastas

### Pasta de Marca (Template)

Cada pasta de marca (`Beyoung/`, `Creamy/`, `Oceane/`, `Ollie/`, `Sallve/`) deve conter:

| Arquivo/Pasta | DescriÃ§Ã£o |
|---------------|-----------|
| `images/` | Imagens dos produtos (nomeadas por `product_id` ou slug) |
| `<marca>_products.csv` | **ObrigatÃ³rio** - CSV com dados padronizados |
| `<marca>_products.json` | **Opcional** - JSON bruto ou exportaÃ§Ã£o alternativa |
| `main.ipynb` | Notebook Jupyter com o scraper e pipeline de limpeza |

### Interface (Dashboard)

| Arquivo/Pasta | DescriÃ§Ã£o |
|---------------|-----------|
| `.streamlit/config.toml` | ConfiguraÃ§Ã£o de tema e aparÃªncia |
| `core/data.py` | Carregamento de dados, validaÃ§Ã£o de schema |
| `core/utils.py` | FunÃ§Ãµes auxiliares (normalizaÃ§Ã£o, parsing) |
| `pages/*.py` | PÃ¡ginas do dashboard (4 pÃ¡ginas) |
| `ui_components/` | Componentes reutilizÃ¡veis (filtros, cards) |
| `Principal.py` | **Entry point** - PÃ¡gina inicial do Streamlit |
| `requirements.txt` | DependÃªncias do dashboard |

### Models (NormalizaÃ§Ã£o)

| MÃ³dulo | FunÃ§Ã£o |
|--------|--------|
| `benefits.py` | Mapeia e normaliza benefÃ­cios dos produtos |
| `category.py` | Classifica produtos em categorias padronizadas |
| `ingredient.py` | Normaliza nomes de ingredientes |
| `skin.py` | Padroniza tipos de pele (oleosa, seca, mista, sensÃ­vel) |

---

## ğŸ“Š Formatos de Dados

### CSV Padronizado

**Colunas obrigatÃ³rias** (`EXPECTED_COLS`):
```
product_id,brand,name,category,price,quantity,benefits,ingredients,skin_types,image_filename,scraped_at
```

#### Exemplo de linha:
```csv
BYG001,Beyoung,SÃ©rum Vitamina C,Serum,49.90,30ml,"hidrataÃ§Ã£o;luminosidade;anti-idade","vitamina c;Ã¡cido hialurÃ´nico;niacinamida","todos os tipos;oleosa",BYG001.jpg,2025-10-22T10:30:00
```

#### DescriÃ§Ã£o dos campos:

| Campo | Tipo | DescriÃ§Ã£o |
|-------|------|-----------|
| `product_id` | string | ID Ãºnico do produto |
| `brand` | string | Nome da marca |
| `name` | string | Nome do produto |
| `category` | string | Categoria (Serum, Hidratante, Cleanser, etc.) |
| `price` | float | PreÃ§o em R$ |
| `quantity` | string | Quantidade/volume (ex: "30ml", "50g") |
| `benefits` | string | Lista separada por `;` ou `\|` |
| `ingredients` | string | Lista separada por `;` ou `\|` |
| `skin_types` | string | Lista separada por `;` ou `\|` |
| `image_filename` | string | Nome do arquivo de imagem |
| `scraped_at` | string | Timestamp ISO8601 da coleta |

### JSON Schema
```json
{
  "product_id": "BYG001",
  "brand": "Beyoung",
  "name": "SÃ©rum Vitamina C",
  "category": "Serum",
  "price": 49.90,
  "quantity": "30ml",
  "benefits": ["hidrataÃ§Ã£o", "luminosidade", "anti-idade"],
  "ingredients": ["vitamina c", "Ã¡cido hialurÃ´nico", "niacinamida"],
  "skin_types": ["todos os tipos", "oleosa"],
  "image_filename": "BYG001.jpg",
  "scraped_at": "2025-10-22T10:30:00"
}
```

---

## âš™ï¸ ConfiguraÃ§Ã£o e ExecuÃ§Ã£o

### 1. Preparar o Ambiente
```bash
# Atualizar pip
python -m pip install --upgrade pip

# Instalar dependÃªncias principais
pip install requests beautifulsoup4 pandas numpy streamlit altair plotly pillow

# Opcional: para scrapers com Selenium
pip install selenium webdriver-manager undetected-chromedriver

# Opcional: para notebooks
pip install jupyter
```

### 2. Gerar os Dados

Para cada marca, execute o notebook de scraping:
```bash
# Abrir Jupyter
jupyter notebook

# Navegue atÃ© a pasta da marca e execute main.ipynb
# Exemplo: marcas/Beyoung/main.ipynb
```

O notebook deve:
1. Coletar dados das pÃ¡ginas da marca
2. Extrair campos relevantes
3. Aplicar normalizaÃ§Ã£o usando `models/`
4. Salvar `<marca>_products.csv` e `<marca>_products.json`

### 3. Rodar o Dashboard
```bash
# Navegar atÃ© a pasta Interface
cd Interface

# Executar o Streamlit
streamlit run Principal.py
```

O dashboard abrirÃ¡ automaticamente em `http://localhost:8501`

---

## ğŸ“± PÃ¡ginas do Dashboard

O dashboard possui **4 pÃ¡ginas** (alÃ©m da pÃ¡gina inicial):

1. **ğŸ“¦ CatÃ¡logo** - VisualizaÃ§Ã£o completa dos produtos com filtros
2. **ğŸ§ª Ingredientes** - AnÃ¡lise e ranking de ingredientes mais comuns
3. **âœ¨ BenefÃ­cios** - EstatÃ­sticas sobre benefÃ­cios prometidos
4. **ğŸ‘¤ Tipos de Pele** - DistribuiÃ§Ã£o de produtos por tipo de pele

---

## ğŸ“¦ DependÃªncias

### Core (obrigatÃ³rio)
```
streamlit>=1.28.0
pandas>=2.0.0
numpy>=1.24.0
```

### VisualizaÃ§Ã£o
```
altair>=5.0.0
plotly>=5.17.0
```

### Scraping
```
requests>=2.31.0
beautifulsoup4>=4.12.0
selenium>=4.15.0  # opcional
```

### Utilidades
```
pillow>=10.0.0
python-dotenv>=1.0.0
```

---

## âœ… Checklist de ImplementaÃ§Ã£o

### Arquivos CrÃ­ticos

- [ ] `Interface/Principal.py` - Entry point do dashboard
- [ ] `Interface/.streamlit/config.toml` - ConfiguraÃ§Ã£o de tema
- [ ] `Interface/core/data.py` - FunÃ§Ãµes de carregamento
- [ ] `Interface/core/utils.py` - FunÃ§Ãµes auxiliares
- [ ] `Interface/pages/1_ğŸ“¦_CatÃ¡logo.py`
- [ ] `Interface/pages/2_ğŸ§ª_Ingredientes.py`
- [ ] `Interface/pages/3_âœ¨_BenefÃ­cios.py`
- [ ] `Interface/pages/4_ğŸ‘¤_Tipos_de_Pele.py`
- [ ] `Interface/requirements.txt`

### Estrutura de Dados

- [ ] CSVs padronizados com colunas `EXPECTED_COLS`
- [ ] FunÃ§Ã£o `load_data()` carregando todos os CSVs
- [ ] FunÃ§Ã£o `validar_schema()` verificando integridade
- [ ] Models de normalizaÃ§Ã£o funcionando

### Template: `config.toml`
```toml
[theme]
primaryColor = "#e91e63"
backgroundColor = "#ffffff"
secondaryBackgroundColor = "#f0f2f6"
textColor = "#0f1720"

[server]
maxUploadSize = 200
```

---

## ğŸ‘¥ Contribuindo

1. Adicione novas marcas criando pasta em `marcas/<nova_marca>/`
2. Siga o template de estrutura (images, CSV, JSON, notebook)
3. Use os mÃ³dulos `models/` para normalizaÃ§Ã£o consistente
4. Teste o carregamento no dashboard antes de commitar

---

## ğŸ“ Notas

- Mantenha `models_sem_filtro/` apenas se necessÃ¡rio para histÃ³rico
- Imagens sÃ£o opcionais mas melhoram a visualizaÃ§Ã£o
- O timestamp `scraped_at` ajuda a rastrear atualizaÃ§Ãµes
- Use `;` como separador padrÃ£o para listas em CSV

---

**Desenvolvido para anÃ¡lise de produtos de skincare brasileiros ğŸ‡§ğŸ‡·âœ¨**
